# 推荐效果评估

## 离线评估
离线评估是采用监督学习的方式，基于从用户行为日志中构建的训练和测试样本，通过一些预先定义好的离线评估指标，对推荐算法进行训练和验证。离线评估有很多优点：不需要将算法部署到生产环境当中，也不需要用户参与，并且很快能看到结果。

### 评估指标
召回算法和排序算法有不同的离线评估指标，[1][学习排序简介]中已经对排序算法中常用的评估指标作了介绍。这里主要介绍召回算法的评估指标。

#### Precision(准确率)
即召回的所有item当中，有多大比例是用户真正感兴趣的（用户产生了点击、浏览等行为）？
#### Recall(召回率)
即用户感兴趣的所有item当中，有多大比例被召回？
准确率和召回率都是越高越好，但是它们是此消彼长的关系。极限情况下，假如所有的item都被召回，那么召回率就是100%，但是准确率会接近0。
#### AUC-ROC
AUC-ROC在[1][学习排序简介]中已有介绍。AUC-ROC的独特之处是不仅可以评估排序算法，很多召回算法也可以用它来评估。
#### Coverage(覆盖度)
即被推荐的商品个数占总商品个数的比例。跟前面几种评估指标不同，覆盖度体现了商品供应商的立场。理想情况下，希望所有商品都有被推荐出去的机会，而不是仅限若干热门商品。

除了上面提到的几种评估指标之外，还有推荐商品的多样性、新颖度等指标。关于这些指标的详细描述可以参考项亮的《推荐系统实践》。

### 训练和测试集的构建

#### 标签匹配

#### 负样本采样

## 在线评估

### 评估指标

### ab-test

[1]: https://github.com/pengxiaoo/recommender-system/blob/master/docs/rank.md
